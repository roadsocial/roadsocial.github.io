<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description" content="DashCop: Automated E-ticket Generation for Two-Wheeler Traffic Violations Using Dashcam Videos.">
    <meta name="keywords" content="dashcop, DashCop, DashCop: Automated E-ticket Generation for Two-Wheeler Traffic Violations Using Dashcam Videos, Automated E-ticket Generation for Two-Wheeler Traffic Violations Using Dashcam Videos, RideSafe, RideSafe-400, Automated E-ticket generation, Traffic violation detection, Motorized two-wheelers, Dashcam video analysis, Triple riding detection, Helmet compliance, Automated traffic monitoring, Road safety technology, Two-wheeler accident prevention, Association-based tracking, License plate recognition, AutomatedEnforcement, TrafficSafety, DashCamAnalysis, TwoWheelerSafety, TripleRiding, HelmetDetection, E-Ticketing, CrossAssociation, RideSafe400, RoadSafetyTech, LicenseRecognition, ViolationDetection, TrafficMonitoring, DynamicTracking, AccidentPrevention">
    <meta name="author" content="Deepti Rawat">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="index, follow">
    <title>RoadSocial: A Diverse VideoQA Dataset and Benchmark for Road Event Understanding from Social Video Narratives</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/icon.png">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-carousel/dist/css/bulma-carousel.min.css"> <!-- for carousel -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <!-- for hovering -->
    <style>
        .tooltip {
            text-decoration: none;
            cursor: pointer;
        }
    </style>
</head>

<body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="https://cvit.iiit.ac.in">
                    <span class="icon">
                        <svg class="svg-inline--fa fa-home fa-w-18" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="home" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" data-fa-i2svg=""><path fill="currentColor" d="M280.37 148.26L96 300.11V464a16 16 0 0 0 16 16l112.06-.29a16 16 0 0 0 15.92-16V368a16 16 0 0 1 16-16h64a16 16 0 0 1 16 16v95.64a16 16 0 0 0 16 16.05L464 480a16 16 0 0 0 16-16V300L295.67 148.26a12.19 12.19 0 0 0-15.3 0zM571.6 251.47L488 182.56V44.05a12 12 0 0 0-12-12h-56a12 12 0 0 0-12 12v72.61L318.47 43a48 48 0 0 0-61 0L4.34 251.47a12 12 0 0 0-1.6 16.9l25.5 31A12 12 0 0 0 45.15 301l235.22-193.74a12.19 12.19 0 0 1 15.3 0L530.9 301a12 12 0 0 0 16.9-1.6l25.5-31a12 12 0 0 0-1.7-16.93z"></path></svg><!-- <i class="fas fa-home"></i> Font Awesome fontawesome.com -->
                    </span>
                </a>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">More Research</a>
                    <div class="navbar-dropdown"><a class="navbar-item" href="https://insaan.iiit.ac.in">INSAAN</a></div>
                </div>
            </div>
        </div>
    </nav>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-3 publication-title">RoadSocial: A Diverse VideoQA Dataset and Benchmark for Road Event Understanding from Social Video Narratives</h1>
                        <h2 class="title is-5 publlication-title">CVPR 2025</h2>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><a href="https://www.linkedin.com/in/chirag-p26495/" class="tooltip" title="Authors contributed equally">Chirag Parikh</a>*,</span>
                            <span class="author-block"><a href="https://www.linkedin.com/in/dpt-xyz/" class="tooltip" title="Authors contributed equally">Deepti Rawat</a>*,</span>
                            <span class="author-block"><a href="https://www.linkedin.com/in/rakshitha-r-t-410a68223/">Rakshitha R. T.</a>,</span>
                            <span class="author-block"><a href="https://www.linkedin.com/in/tathagata-ghosh-85728192/">Tathagata Ghosh</a>,</span>
                            <span class="author-block"><a href="https://ravika.github.io">Ravi Kiran Sarvadevabhatla</a></span>
                        </div>
                        <div class="is-size-5 publication-authors"><span class="author-block">IIIT Hyderabad</span></div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark" disabled style="pointer-events: none; opacity: 0.6;">
                                        <span class="icon"><i class="fas fa-file-pdf"></i></span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <!-- ArXiv Link.-->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark" disabled style="pointer-events: none; opacity: 0.6;">
                                        <span class="icon"><i class="ai ai-arxiv"></i></span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Poster Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark" disabled style="pointer-events: none; opacity: 0.6;">
                                        <span class="icon"><svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com --></span>
                                        <span>Poster</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark" disabled style="pointer-events: none; opacity: 0.6;">
                                        <span class="icon"><svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com --></span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark" disabled style="pointer-events: none; opacity: 0.6;">
                                        <span class="icon"><i class="far fa-images"></i></span>
                                        <span>Data</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- for carousel -->
    <section class="section" style="background-color: #f0f0f0; width: 100%; padding-top: 25px; padding-bottom: 0px;">
        <div class="container" style="margin-top: -20px; text-align: center;">
            <div id="carousel-demo" class="carousel">
                <div class="item-1"><img src="./static/images/1.jpg" alt="Image 1"></div>
                <div class="item-2"><img src="./static/images/2.jpg" alt="Image 2"></div>
                <div class="item-3"><img src="./static/images/3.jpg" alt="Image 3"></div>
                <div class="item-3"><img src="./static/images/4.jpg" alt="Image 4"></div>
                <div class="item-3"><img src="./static/images/5.jpg" alt="Image 5"></div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            We introduce <i>RoadSocial</i>, a large-scale, diverse VideoQA dataset tailored for generic road event understanding from social media narratives. Unlike existing datasets limited by regional bias, viewpoint bias and expert-driven annotations, RoadSocial captures the global complexity of road events with varied geographies, camera viewpoints (CCTV, handheld, drones) and rich social discourse.
                        </p>
                        <p>
                            Our scalable semi-automatic annotation framework leverages Text LLMs and Video LLMs to generate comprehensive question-answer pairs across 12 challenging QA tasks, pushing the boundaries of road event understanding.
                        </p>
                        <p>
                            RoadSocial is derived from social media videos spanning 14M frames and 414K social comments, resulting in a dataset with 13.2K videos, 674 tags and 260K high-quality QA pairs. We evaluate 18 Video LLMs (open-source and proprietary, driving-specific and general-purpose) on our road event understanding benchmark. We also demonstrate RoadSocial's utility in improving road event understanding capabilities of general-purpose Video LLMs.
                        </p>
                    </div>
                </div>
            </div>
            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered mt-5"> <!-- Added mt-5 for more top margin -->
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Video</h2>
                    <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/cB5kziXLDFg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section pt-3">  <!-- Added pt-3 to reduce top padding of section -->
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3 mt-5">Our Dataset</h2>
                    <h3 class="title is-4">How RoadSocial Compares to Existing Video Datasets</h3>
                    <div class="content has-text-justified">
                        <p>
                            Existing video datasets capture road events through surrounding entity actions, traffic interactions, and safety-critical scenarios. However, many of these datasets are geographically constrained, limiting their ability to generalize across diverse traffic norms. To address this limitation, RoadSocial includes videos from diverse sources (e.g., drone, handheld, CCTV) alongside social discourse, ensuring a broader and more inclusive perspective on road events.
                        </p>
                        <p>
                            Unlike previous datasets that focus primarily on ego-centric tasks, RoadSocial introduces novel QA tasks designed to evaluate model robustness against hallucinations, diverse viewpoints, and geographical awareness. This enables a more comprehensive and generalizable understanding of road events.
                        </p>
                    </div>
                    <div class="content has-text-centered" style="padding: 0; margin: 0;"> <!-- Removed any default margins -->
                        <figure style="margin: 0; padding: 0; width: 100%;"> <!-- Added full width and removed margins -->
                            <img src="./static/images/roadSocial_comparison.png" alt="Comparison of RoadSocial with existing Datasets" style="width: 100%; height: auto; display: block;" loading="lazy" />  <!-- Force full width -->
                            <figcaption style="margin-top: 1rem;">Comparison of RoadSocial with existing road event understanding datasets. TG: Temporal Grounding, AV: Adversarial, IC: Incompatible, Loc: Geographical Location. Internet-sourced videos do not contain LiDAR or CAN bus data. <p><span style="color: orange;">Orange</span>: Additional annotations added to existing datasets. <span style="color: blue;">Blue</span>: New datasets.</p></figcaption>
                        </figure>
                    </div>
                </div>
            </div>

            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h3 class="title is-4">Benchmarking Video LLMs on RoadSocial-QA</h3>
                    <div class="content has-text-justified">
                        <p>
                            Our evaluation of Video LLMs on RoadSocial-QA highlights key trends in road event understanding. Tarsier-34B leads in overall performance, while IXC-2.5-7B excels in road-event-specific tasks. General-purpose models consistently outperform driving-specific ones, indicating room for improvement in domain-specific adaptations.
                        </p>
                        <p>
                            Challenges & Insights: Models struggle with complex reasoning (Why, Consequence, Temporal Grounding) and hallucination, particularly in mismatched QAs. Fine-tuning LLaVA-OV-7B on RoadSocial boosts its performance by 19.1%, underscoring the dataset’s impact in enhancing general-purpose Video LLMs for real-world driving scenarios.
                        </p>
                    </div>
                    <div class="content has-text-centered" style="padding: 0; margin: 0;"> <!-- Removed any default margins -->
                        <figure style="margin: 0; padding: 0; width: 100%;"> <!-- Added full width and removed margins -->
                            <img src="./static/images/VLM_benchmark.png" 
                                alt="Video LLMs are benchmarked on RoadSocial-QA"
                                style="width: 100%; height: auto; display: block;" loading="lazy" />  <!-- Force full width -->
                            <figcaption style="margin-top: 1rem;">
                                <p>
                                    Evaluation of Video LLMs on 12 QA tasks highlights performance trends across open-source (<span style="background-color: #cce2d7; padding: 2px;">driving-specific</span> and <span style="background-color: #fddfec; padding: 2px;">general-purpose</span>), <span style="background-color: #f0eeff; padding: 2px;">closed-source</span>, and <span style="background-color: #d9d9d9; padding: 2px;">fine-tuned</span> models. 
                                    Key reasoning categories include <span style="font-weight: bold;">Factual</span> - Where <span style="color: #00000061; padding: 2px;">(WR)</span>, Key Entities <span style="color: #00000061; padding: 2px;">(KE)</span>, Viewpoint <span style="color: #00000061; padding: 2px;">(VP)</span>, <span style="font-weight: bold;">Complex</span> - Description <span style="color: #00000061; padding: 2px;">(DS)</span>, Why <span style="color: #00000061; padding: 2px;">(WY)</span>, Consequence <span style="color: #00000061; padding: 2px;">(CQ)</span>, Temporal Grounding <span style="color: #00000061; padding: 2px;">(TG)</span>, <span style="font-weight: bold;">Imaginative</span> - Advisory <span style="color: #00000061; padding: 2px;">(AD)</span>, Introspection <span style="color: #00000061; padding: 2px;">(IN)</span>, Counterfactual <span style="color: #00000061; padding: 2px;">(CF)</span>, and <span style="font-weight: bold;">Hallucination</span> - Adversarial <span style="color: #00000061; padding: 2px;">(AV)</span>, Incompatible <span style="color: #00000061; padding: 2px;">(IC)</span> tasks.
                                    GPT-3.5 scores are reported for most tasks, while mAP@.3:.7% is used for Temporal Grounding. Overall and category-wise averages are provided, with scores (scale 0 to 100) color-coded from <span style="background-color: #ddf6fd; padding: 2px;">low</span> to <span style="background-color: #ff7373; padding: 2px;">high</span>
                                </p>    
                            </figcaption>
                        </figure>
                    </div>
                    <!-- References spanning both columns -->
                    <div class="columns is-centered mt-4"> <!-- Changed to mt-2 -->
                        <div class="column is-full pt-0">
                            <div class="content has-text-justified">
                                <p class="mt-0"> <!-- Added mt-0 to remove any top margin from paragraph -->
                                    References: InternVL2 <a href="https://arxiv.org/abs/2312.14238">[4]</a>; MM-AU <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Fang_Abductive_Ego-View_Accident_Video_Understanding_for_Safe_Driving_Perception_CVPR_2024_paper.pdf">[5]</a>; VITA <a href="https://arxiv.org/abs/2408.05211">[6]</a>; BDD-X <a href="https://arxiv.org/abs/1807.11546">[8]</a>; LLaVA-OV <a href="https://arxiv.org/abs/2408.03326">[10]</a>; ARIA <a href="https://arxiv.org/html/2410.05993v1">[11]</a>; Dolphin <a href="https://arxiv.org/abs/2312.00438">[13]</a>; DRAMA <a href="https://openaccess.thecvf.com/content/WACV2023/html/Malla_DRAMA_Joint_Risk_Localization_and_Captioning_in_Driving_WACV_2023_paper.html">[15]</a>; LingoQA <a href="https://arxiv.org/abs/2312.14115">[16]</a>; GPT-4o <a href="https://openai.com/index/hello-gpt-4o/">[18]</a>; Rank2Tell <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Sachdeva_Rank2Tell_A_Multimodal_Driving_Dataset_for_Joint_Importance_Ranking_and_WACV_2024_paper.pdf">[24]</a>; LongVU <a href="https://arxiv.org/abs/2410.17434">[25]</a>; DriveLM <a href="https://arxiv.org/abs/2312.14150">[26]</a>; ROAD <a href="https://ieeexplore.ieee.org/document/9712346">[27]</a>; Gemini-1.5-Pro <a href="https://arxiv.org/abs/2312.11805">[28]</a>; Tarsier <a href="https://arxiv.org/abs/2407.00634">[30]</a>; Qwen2-VL <a href="https://arxiv.org/html/2409.12191v1">[31]</a>; SUTD-TrafficQA <a href="https://arxiv.org/abs/2103.15538">[32]</a>; BDD-OIA <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Explainable_Object-Induced_Action_Decision_for_Autonomous_Vehicles_CVPR_2020_paper.pdf">[33]</a>; Mini-CPM-V <a href="https://arxiv.org/abs/2408.01800">[35]</a>; IXC-2.5 <a href="https://arxiv.org/html/2407.03320v1">[36]</a>; LLaVA-Video <a href="https://arxiv.org/abs/2410.02713">[37]</a>
                                </p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#">
                    <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                </a>
                <a class="icon-link" href="https://github.com/roadsocial/roadsocial.github.io/tree/main" disabled="">
                    <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content"><p>This website was adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p></div>
                </div>
            </div>
        </div>
    </footer>

    <!-- for carousel -->
    <script src="https://cdn.jsdelivr.net/npm/bulma-carousel/dist/js/bulma-carousel.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function () {
            bulmaCarousel.attach('#carousel-demo', {
                slidesToScroll: 1,
                slidesToShow: 1,
                autoplay: true,
                autoplaySpeed: 3000,
                infinite: true
            });
        });
    </script>

</body>
</html>
